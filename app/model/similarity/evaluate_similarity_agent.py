import logging
import time
import torch
from sentence_transformers import util
from app.web_socket.notifier import notify_progress
import app.core.models as models


threshold_e5=0.8
threshold_labse=0.7
threshold_bert=0.8
threshold_comet=0.5


def _encode_with_model(model, inputs):
    """
    ì£¼ì–´ì§„ ëª¨ë¸ë¡œ inputs ë¦¬ìŠ¤íŠ¸ë¥¼ ì¸ì½”ë”©í•˜ê³ , ê²°ê³¼ë¥¼ torch.Tensorë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    emb = model.encode(inputs)
    return emb if isinstance(emb, torch.Tensor) else torch.tensor(emb)


def _compute_e5(original: str, translated: str):
    """
    E5 ëª¨ë¸ë¡œ ì˜ë¯¸ ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°
    """
    emb_tensor = _encode_with_model(
        models.model_e5,
        [f"query: {original}", f"passage: {translated}"]
    )
    return util.pytorch_cos_sim(emb_tensor[0], emb_tensor[1]).item()


def _compute_labse(original: str, translated: str):
    """
    LaBSE ëª¨ë¸ë¡œ ì§ì—­ ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°
    """
    emb2_tensor = _encode_with_model(
        models.model_labse,
        [original, translated]
    )
    return util.pytorch_cos_sim(emb2_tensor[0], emb2_tensor[1]).item()


def _compute_bertscore(original: str, translated: str):
    """
    BERTScore ëª¨ë¸ë¡œ precision, recall, f1 ì ìˆ˜ ê³„ì‚°
    """
    p, r, f1 = models.bert_scorer.score([original], [translated])
    return p.item(), r.item(), f1.item()


def _compute_comet(original:str, translated: str):
    """
    comet ëª¨ë¸ë¡œ comet score ê³„ì‚°
    """
    data = [
        {
            "src": original,
            "mt": translated,
        }
    ]
    logging.info("data: {}".format(data))
    model_output = models.model_comet.predict(data, batch_size=8, gpus=0)
    return model_output.system_score


async def evaluate_dual_similarity(
    task_name: str,
    original: str,
    translated: str,
    threshold_e5_good: float = 0.8,
    threshold_labse_good: float = 0.7
) -> dict:
    """
    ì„¸ ë‹¨ê³„(E5, LaBSE, BERTScore)ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ë©°,
    ì§„í–‰ë¥ ì„ WebSocketìœ¼ë¡œ ì „ì†¡í•˜ê³  ìµœì¢… ìœ ì‚¬ë„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    start = time.time()
    await notify_progress(task_name, 0)
    logging.info(f"ğŸ“ Original: {original}")
    logging.info(f"ğŸˆ¶ Translated: {translated}")

    # ë‹¨ê³„ë³„ ê³„ì‚° ë° ì§„í–‰ë¥  ì „ì†¡
    step_funcs = [
        ("E5", _compute_e5),
        ("LaBSE", _compute_labse),
        ("BERTScore", _compute_bertscore),
        ("comet", _compute_comet)
    ]
    total_steps = len(step_funcs)
    sim_e5 = sim_labse = None
    p = r = f1 = None
    comet_score = None

    for idx, (name, func) in enumerate(step_funcs, start=1):
        # í•¨ìˆ˜ í˜¸ì¶œ
        result = func(original, translated)
        # ê²°ê³¼ ì €ì¥
        if name == "E5":
            sim_e5 = result
        elif name == "LaBSE":
            sim_labse = result
        elif name == "BERTScore":
            p, r, f1 = result
        else:
            comet_score = result

        # ì§„í–‰ë¥  ê³„ì‚° ë° ì•Œë¦¼
        progress = int(idx / total_steps * 100)
        await notify_progress(task_name, progress)
        logging.info(f"Step '{name}' completed, progress={progress}%")

    # ì¢…í•© íŒë‹¨
    if sim_e5 is None or sim_labse is None or p is None:
        err = "Similarity computation failed"
        logging.error(f"âŒ {err} for task {task_name}")
        await notify_progress(task_name, -1, error=err)
        return {}

    descriptions = []

    if sim_e5 > threshold_e5_good and sim_labse > threshold_labse_good:
        descriptions.append(
            f"âœ… ì§ì—­ ê°€ëŠ¥ì„± ë†’ìŒ (E5: {sim_e5:.2f} â‰¥ {threshold_e5}, "
            f"LaBSE: {sim_labse:.2f} â‰¥ {threshold_labse})"
        )
    elif sim_e5 > threshold_e5_good:
        f"âœï¸ ì˜ì—­ ê°€ëŠ¥ì„± ìˆìŒ (E5: {sim_e5:.2f} â‰¥ {threshold_e5}, "
        f"LaBSE: {sim_labse:.2f} < {threshold_labse})"

    elif sim_labse > threshold_labse_good:
        descriptions.append(
            f"ğŸ“– ì§ì—­ ìœ ì‚¬ì„±ë§Œ ë†’ìŒ (E5: {sim_e5:.2f} < {threshold_e5}, "
            f"LaBSE: {sim_labse:.2f} â‰¥ {threshold_labse})"
        )
    else:
        descriptions.append(
            f"âš ï¸ ì˜ë¯¸ ì°¨ì´ í¼ (E5: {sim_e5:.2f}, LaBSE: {sim_labse:.2f}); "
            "COMET score í™•ì¸ ìš”ë§"
        )

    # BERTScore í‰ê°€
    if f1 >= threshold_bert:
        descriptions.append(
            f"ğŸ‘ ë‹¨ì–´ ë‹¨ìœ„ ì˜ë¯¸ ìœ ì‚¬ë„ ìš°ìˆ˜ (BERTScore F1: {f1:.2f} â‰¥ {threshold_bert})"
        )
    else:
        descriptions.append(
            f"ğŸ‘ ë‹¨ì–´ ë‹¨ìœ„ ì˜ë¯¸ ìœ ì‚¬ë„ ë¶€ì¡± (BERTScore F1: {f1:.2f} < {threshold_bert})"
        )

    # COMET í‰ê°€ ì¶”ê°€
    if comet_score >= threshold_comet:
        descriptions.append(
            f"ğŸ¯ ë²ˆì—­ í’ˆì§ˆ ìš°ìˆ˜ (COMET: {comet_score:.2f} â‰¥ {threshold_comet})"
        )
    else:
        descriptions.append(
            f"â—ï¸ ë²ˆì—­ í’ˆì§ˆ ë¯¸í¡ (COMET: {comet_score:.2f} < {threshold_comet})"
        )

    execution_time = time.time() - start
    logging.info(f"E5 ì˜ë¯¸ ìœ ì‚¬ë„: {sim_e5:.4f}")
    logging.info(f"LaBSE ì§ì—­ ìœ ì‚¬ë„: {sim_labse:.4f}")
    logging.info(f"BERTScore - P: {p:.4f}, R: {r:.4f}, F1: {f1:.4f}")
    logging.info(f"comet score: {comet_score:.4f}")
    logging.info(f"â± ì‹¤í–‰ ì‹œê°„: {execution_time:.2f}s | âœ… completed similarity for task {task_name}")

    return {
        "original_text": original,
        "translated_text": translated,
        "e5_semantic_similarity": round(sim_e5, 4),
        "labse_literal_similarity": round(sim_labse, 4),
        "bertscore": {"precision": round(p, 4), "recall": round(r, 4), "f1": round(f1, 4)},
        "comet_score": comet_score,
        "description": "\n".join(descriptions) + "\n",
        "execution_time": round(execution_time, 2)
    }
